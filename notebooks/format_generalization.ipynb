{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a577e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import hmean\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "pal = sns.color_palette(\"deep\", 10)\n",
    "model_colors = {\n",
    "    \"Ablation\": pal[7],\n",
    "    \"ICL-FT\": pal[8],\n",
    "    \"RAG-FT\": pal[6],\n",
    "    \"MemLLM\": pal[9],\n",
    "    \"GNM\": pal[0],\n",
    "}\n",
    "\n",
    "# Data from the table\n",
    "# data = {\n",
    "#     'Dataset': ['train', 'test-id', 'test-ood'],\n",
    "#     'RAG-FT': [100, 49.4, 0.0],\n",
    "#     'ICL-FT': [100, 63.3, 4.4],\n",
    "#     'GNM': [100, 100, 67.4]\n",
    "# }\n",
    "\n",
    "data = {\n",
    "    'Dataset': ['ICL-FT', 'RAG-FT','GNM'],\n",
    "    'train': [100, 100, 100],\n",
    "    'test-id': [63, 49, 100],\n",
    "    'test-ood': [4.4, 0.0, 67]\n",
    "}\n",
    "\n",
    "data_df = pd.DataFrame(data)\n",
    "\n",
    "# Metrics to plot (excluding Acc. since it's 0 for two models)\n",
    "metrics = ['ICL-FT', 'RAG-FT', \"GNM\"]\n",
    "metric_labels = ['ICL-FT', 'RAG-FT', \"GNM\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 3))\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "bar_width = 0.25  # Reduced width to prevent overlap\n",
    "\n",
    "# Colors for arrows and bars\n",
    "id_color = \"#CC8426\"  # Blue for in-distribution\n",
    "ood_color = \"#7213AD\"  # Orange for out-of-distribution\n",
    "\n",
    "# Plot bars for GNM, RAG-FT, ICL-FT, grouped by the model\n",
    "bars1 = ax.bar(x - bar_width, data_df['train'], width=bar_width, label='train formats', color='#6B7280', alpha=0.9)\n",
    "bars2 = ax.bar(x, data_df['test-id'], width=bar_width, label='test-id formats', color=id_color, alpha=0.9)\n",
    "bars3 = ax.bar(x + bar_width, data_df['test-ood'], width=bar_width, label='test-ood formats', color=ood_color, alpha=0.9)\n",
    "\n",
    "# Add data labels on each bar (white text inside for tall bars, black text on top for short bars)\n",
    "threshold = 15  # Values below this go on top in black\n",
    "\n",
    "for i, (bar, value) in enumerate(zip(bars1, data_df['train'])):\n",
    "    if value >= threshold:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() - 5, f'{value:.0f}', \n",
    "                ha='center', va='top', fontsize=10, fontweight='normal', color='white')\n",
    "    elif value >= 0:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1.5, f'{value:.0f}', \n",
    "                ha='center', va='bottom', fontsize=10, fontweight='normal', color='black')\n",
    "\n",
    "for i, (bar, value) in enumerate(zip(bars2, data_df['test-id'])):\n",
    "    if value >= threshold:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() - 5, f'{value:.0f}', \n",
    "                ha='center', va='top', fontsize=10, fontweight='normal', color='white')\n",
    "    elif value >= 0:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1.5, f'{value:.0f}', \n",
    "                ha='center', va='bottom', fontsize=10, fontweight='normal', color='black')\n",
    "\n",
    "for i, (bar, value) in enumerate(zip(bars3, data_df['test-ood'])):\n",
    "    if value >= threshold:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() - 5, f'{value:.0f}', \n",
    "                ha='center', va='top', fontsize=10, fontweight='normal', color='white')\n",
    "    elif value >= 0:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1.5, f'{value:.0f}', \n",
    "                ha='center', va='bottom', fontsize=10, fontweight='normal', color='black')\n",
    "\n",
    "ax.set_ylabel('Format Accuracy (%)', fontsize=12)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metric_labels, fontsize=12)\n",
    "ax.set_ylim(0, 105) \n",
    "ax.legend(fontsize=11, loc='upper left', bbox_to_anchor=(0.12, 0.98), frameon=False, ncol=1)\n",
    "ax.grid(axis='y', alpha=0.3, zorder=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../plots/format_generalization.png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "pal = sns.color_palette(\"deep\", 10)\n",
    "model_colors = {\n",
    "    \"Ablation\": pal[7],\n",
    "    \"ICL-FT\": pal[8],\n",
    "    \"llama3_ft\": pal[8],\n",
    "    \"RAG-FT\": pal[5],\n",
    "    \"rag_trained\": pal[6],\n",
    "    \"MemLLM\": pal[9],\n",
    "    \"GNM\": pal[0],\n",
    "    \"gnm\": pal[0]\n",
    "}\n",
    "\n",
    "# Wilson score interval CI function - returns symmetric error for visual consistency\n",
    "def wilson_ci(p, n, z=1.96):\n",
    "    \"\"\"Returns 95% CI half-width using Wilson score interval (p in 0-100 scale).\n",
    "    Makes error bars visually symmetric by using max of lower/upper error.\n",
    "    \"\"\"\n",
    "    p_prop = p / 100  # Convert percentage to proportion\n",
    "    \n",
    "    denom = 1 + z**2 / n\n",
    "    center = (p_prop + z**2 / (2*n)) / denom\n",
    "    margin = z * np.sqrt(p_prop * (1 - p_prop) / n + z**2 / (4 * n**2)) / denom\n",
    "    \n",
    "    lower = center - margin\n",
    "    upper = center + margin\n",
    "    \n",
    "    # Compute asymmetric errors\n",
    "    lower_err = max(0, (p_prop - lower) * 100)\n",
    "    upper_err = max(0, (upper - p_prop) * 100)\n",
    "    \n",
    "    # Use the max of the two for symmetric display\n",
    "    symmetric_err = max(lower_err, upper_err)\n",
    "    \n",
    "    return symmetric_err\n",
    "\n",
    "# Sample counts for each category\n",
    "n_samples = {\n",
    "    'train': 200,\n",
    "    'test-id': 35,\n",
    "    'test-ood': 216\n",
    "}\n",
    "\n",
    "## now make a version of this graph that swaps it so that the legend is RAG-FT, ICL-FT, GNM, and the grouped bars are train-formats, test-id formats, test-ood formats\n",
    "fig, ax = plt.subplots(figsize=(6.5, 2.1))\n",
    "categories = ['train', 'test-id', 'test-ood']\n",
    "x = np.arange(len(categories))\n",
    "bar_width = 0.25  # Reduced width to prevent overlap\n",
    "\n",
    "# Plot bars for each model and store them for labeling\n",
    "all_bars = []\n",
    "all_cis = []\n",
    "for i, model_name in enumerate(data_df['Dataset']):\n",
    "    model_data = data_df[data_df['Dataset'] == model_name]\n",
    "    offset = (i - 1) * bar_width  # center the bars\n",
    "    values = model_data[categories].values.flatten()\n",
    "    \n",
    "    # Compute symmetric Wilson CIs for each category\n",
    "    cis = [wilson_ci(values[j], n_samples[cat]) for j, cat in enumerate(categories)]\n",
    "    \n",
    "    bars = ax.bar(x + offset, values, \n",
    "           width=bar_width, label=model_name, color=model_colors[model_name], alpha=0.9,\n",
    "           yerr=cis, capsize=0, error_kw={'linewidth': 1.5})\n",
    "    all_bars.append((bars, values))\n",
    "    all_cis.append(cis)\n",
    "\n",
    "# Add data labels - at bottom of bars, except for short bars which go above error bar\n",
    "for (bars, values), cis in zip(all_bars, all_cis):\n",
    "    for bar, value, ci in zip(bars, values, cis):\n",
    "        if value >= 25:  # Tall enough bars: label at bottom inside\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, 3, f'{value:.0f}', \n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='normal', color='black')\n",
    "        else:  # Short bars: label above the error bar\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, value + ci + 2, f'{value:.0f}', \n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='normal', color='black')\n",
    "        \n",
    "ax.set_xticks(x)\n",
    "# set tick labels to pretty names for categories\n",
    "ax.set_xticklabels(['Train Formats', 'Val-ID Formats', 'Test-OOD Formats'], fontsize=14)\n",
    "ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(0.63, 1.05), frameon=False, ncol=1)\n",
    "ax.set_ylabel('Format Accuracy (%)', fontsize=14)\n",
    "ax.set_ylim(0, 105)\n",
    "ax.grid(axis='y', alpha=0.3, zorder=0)\n",
    "plt.savefig(\"../plots/format_generalization_swapped.png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ec559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import hmean\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "pal = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7424d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_means(A):\n",
    "    A = np.asarray(A)\n",
    "    n, m = A.shape\n",
    "    assert n == m, \"expect square matrix\"\n",
    "    return np.array([A.diagonal(offset=k).mean() for k in range(-(n-1), n)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa10031",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"memoryllm\": \"MemLLM\",\n",
    "    \"gnm_ablation\": \"GNM (Ablation)\",\n",
    "    \"gnm\": \"GNM\",\n",
    "    \n",
    "}\n",
    "\n",
    "model_keys = list(models.keys())\n",
    "model_names = list(models.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1aa9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keys, model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_colors = {\n",
    "    \"llama3_ft\": pal[1],\n",
    "    \"rag_trained\": pal[2],\n",
    "    \"memoryllm\": pal[4],\n",
    "    \"gnm\": pal[0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614aed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "\n",
    "for model_key, model_name in models.items():\n",
    "\n",
    "    data_root = f\"../data/gnm_experiments/mixed_documents/{model_key}/summary.json\"\n",
    "\n",
    "    # Open the file and load the data\n",
    "    with open(data_root, 'r') as json_file:\n",
    "        data_dict = json.load(json_file)\n",
    "\n",
    "    data[model_key] = data_dict\n",
    "    data[model_key][\"model_name\"] = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_rollout = 10\n",
    "step_0 = len_rollout-1\n",
    "\n",
    "rows = []\n",
    "\n",
    "for k, v in data.items():\n",
    "\n",
    "    total_refusal_score = hmean(\n",
    "        np.array([\n",
    "            # v['refusal_accuracy'][0],\n",
    "            v['refusal_precision'][0],\n",
    "            v['refusal_recall'][0],\n",
    "            # v['refusal_specificity'][0],\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    #######################\n",
    "    ### All Upper Triangle\n",
    "    #######################\n",
    "\n",
    "    print(k)\n",
    "\n",
    "    fa_mat = np.array(v[\"fact_accuracy_matrix\"])[0][:len_rollout, :len_rollout]\n",
    "    all_acc = np.mean(fa_mat[np.triu_indices_from(fa_mat, k=0)])\n",
    "    print(\"all_acc\", all_acc)\n",
    "\n",
    "    f_acc_diags = diag_means(fa_mat)[step_0:]\n",
    "\n",
    "    fs_mat = np.array(v[\"fact_specificity_matrix\"])[0][:len_rollout, :len_rollout]\n",
    "    all_spec = np.mean(fs_mat[np.triu_indices_from(fs_mat, k=0)])\n",
    "    print(\"all_spec\", all_spec)\n",
    "\n",
    "    f_spec_diags = diag_means(fs_mat)[step_0:]\n",
    "\n",
    "    fs_mat = np.array(v[\"fact_selectivity_matrix\"])[0][:len_rollout, :len_rollout]\n",
    "    all_sel = np.mean(fs_mat[np.triu_indices_from(fs_mat, k=0)])\n",
    "    print(\"all_sel\", all_sel)\n",
    "\n",
    "    f_sel_diags = diag_means(fs_mat)[step_0:]\n",
    "\n",
    "    total_all_score = harmonic_mean = hmean(\n",
    "        np.array(\n",
    "            [\n",
    "                all_acc,\n",
    "                all_spec,\n",
    "                all_sel\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    print(\"total all score\", total_all_score)\n",
    "    print(\"---\")\n",
    "\n",
    "    f_score_diags = np.mean(np.vstack([f_acc_diags, f_spec_diags, f_sel_diags]), 0)\n",
    "\n",
    "    data[k][\"fact_score_retention\"] = f_score_diags\n",
    "    \n",
    "    refusal_f1_over_time = np.mean(np.vstack([v[\"refusal_precision_over_time\"], v[\"refusal_recall_over_time\"]]), 0)[:len_rollout]\n",
    "    print(refusal_f1_over_time)\n",
    "    \n",
    "    scale = 100\n",
    "\n",
    "    row = [\n",
    "        # k,\n",
    "        v[\"model_name\"],\n",
    "        total_all_score*scale,\n",
    "        all_acc*scale,\n",
    "        all_spec*scale,\n",
    "        all_sel*scale,\n",
    "        v['format_accuracy'][0]*scale,\n",
    "        v['format_selectivity'][0]*scale,\n",
    "        total_refusal_score*scale,\n",
    "        v['refusal_precision'][0]*scale,\n",
    "        v['refusal_recall'][0]*scale,\n",
    "    ]\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "columns = [\n",
    "    # \"model_key\",\n",
    "    \"model_name\",\n",
    "    \"total_all_score\",\n",
    "    \"all_fact_accuracy\",\n",
    "    \"all_fact_specificity\",\n",
    "    \"all_fact_selectivity\",    \n",
    "    'format_accuracy',\n",
    "    'format_selectivity',\n",
    "    'total_refusal_score',\n",
    "    'refusal_precision',\n",
    "    'refusal_recall',\n",
    "\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(rows, columns=columns)\n",
    "results_df.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62650ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e3722",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_cols = [\n",
    "    'model_name', \n",
    "    'total_all_score', \n",
    "    'all_fact_selectivity', \n",
    "    'format_accuracy',  \n",
    "    'total_refusal_score',\n",
    "]\n",
    "\n",
    "ablation_comp_models = [\"MemLLM\", \"GNM\", \"GNM (Ablation)\"]\n",
    "\n",
    "ablation_df = results_df[ablation_cols]\n",
    "ablation_df = ablation_df[ablation_df[\"model_name\"].isin(ablation_comp_models)]\n",
    "ablation_df.columns = [\"model_name\", \"Facts (Overall)\", \"Facts (Sel.)\", \"Format (Acc.)\", \"Refusal (F1)\"]\n",
    "ablation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41f3239",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ablation_df.to_latex(index=False, float_format=\"%.1f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c43264d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226c5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86edda1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
